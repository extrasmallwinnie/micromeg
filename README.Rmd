---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# micromeg

<!-- badges: start -->
<!-- badges: end -->

The goal of `micromeg` is to guide you through *my* typical microbiome 16S pipeline, and to document and share convenience functions I've created for data analysis and processing.    

This package does not create any brand new functionality and was built on the great work of [others](https://github.com/extrasmallwinnie/micromeg/?tab=readme-ov-file#acknowledgements). Much of what it does can be accomplished with other packages. For example, [phyloseq](https://bioconductor.org/packages/release/bioc/html/phyloseq.html) provides many similar tools, and is very well-documented and commonly used (I use it myself!) and so may be better for your purposes.    
    
Other R packages heavily used here include:    
1. [tidyverse](https://tidyverse.tidyverse.org) ecosystem   
2. [vegan](https://cran.r-project.org/web/packages/vegan/index.html)   
3. [dada2](https://benjjneb.github.io/dada2/)   
4. [maaslin3](https://huttenhower.sph.harvard.edu/maaslin3/)        


I started my career in microbiome research at the bench and had to [ELI5](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExY3hrYzg1a2I2eGtuNWIwYTRqNDMzNGE0cWlkNGE5OXB4ZHV1YXY4dCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/WsNbxuFkLi3IuGI9NU/giphy.gif) to myself how to process and analyze "big data". I've spent a ton of time poring over and experimenting with [others' code](https://github.com/extrasmallwinnie/micromeg/?tab=readme-ov-file#acknowledgements). Likely, the ideal candidate to benefit from `micromeg` would be another bench scientist without much formal statistics or bioinformatics training. Fair warning, if you already have a strong stats/informatics background, this may not be of much use for you!    

## Installation

You can install the development version of micromeg from [GitHub](https://github.com/extrasmallwinnie/micromeg/) with:

``` r
# install.packages("pak")
pak::pak("extrasmallwinnie/micromeg")
```

## My Usual Workflow

I've listed the steps that I usually take with 16S data, some of which will be demonstrated below with some made up data.    

1. Do the lab work to extract DNA, make libraries, submit for sequencing, etc. [Go &darr;](https://github.com/extrasmallwinnie/micromeg?tab=readme-ov-file#step-1-the-lab-work)        
2. Get the data from the sequencing core. [Go &darr;](https://github.com/extrasmallwinnie/micromeg?tab=readme-ov-file#step-2-sequencing)   
3. Process the data through [dada2](https://benjjneb.github.io/dada2/) then [decontam](https://benjjneb.github.io/decontam/vignettes/decontam_intro.html) to generate a cleaned [ASV (amplicon sequencing variant) count table and its associated taxonomy table](https://www.nature.com/articles/nmeth.3869). [Go &darr;](&darr;)   
4. Create a "metadata" file with pertinent information on the samples and controls in your run. [Go to example &darr;](https://github.com/extrasmallwinnie/micromeg/?tab=readme-ov-file#metadata)
5. Do some basic sanity checking on the metadata, ASV, and taxonomy objects. [Go &darr;](https://github.com/extrasmallwinnie/micromeg?tab=readme-ov-file#step-5-sanity-check)    
6. Check the quality of the sequencing data by examining both the positive and negative controls, and additionally how the controls compare to your real samples. [Go &darr;](https://github.com/extrasmallwinnie/micromeg?tab=readme-ov-file#step-6-quality-check)      
7. Alpha diversity (vegan).   
8. Beta diversity (vegan).   
9. Differential abundance (maaslin3).   


```{r empty}
```
### Step 1: the lab work

I'm not going to get into much detail here. More TBA.  Both negative and positive controls are very important! Why, and what are those? Read more here: ^[1](https://pubmed.ncbi.nlm.nih.gov/25387460/),^ ^[2](https://pubmed.ncbi.nlm.nih.gov/27239228/),^ ^[3](https://bmcmicrobiol.biomedcentral.com/articles/10.1186/s12866-020-01839-y),^ ^[4](https://bmcmicrobiol.biomedcentral.com/articles/10.1186/s12866-016-0738-z),^ ^[5](https://journals.asm.org/doi/10.1128/msystems.00062-16)^

 
```{r empty}
```

### Step 2: Sequencing

### Step 3: Data processing

### Step 4: Metadata

#### Load in example data
     
I've made up an example study where nasal swabs were taken from people who were either "healthy" or "sick" at the time of sampling. We've collected from each participant their health status, their age at collection, sex, and a simplified location category (in this case, 'rural' or 'urban'). There were also four total lab negative controls (two extraction and two PCR negative controls) and one lab positive control containing a known mock community of bacteria. 

##### Metadata

This package includes an example data set.        

Let's look at the example metadata object `exampleMetadata`:

```{r examplemeta}
library(micromeg)

exampleMetadata
```

This metadata object is a tibble (because I personally prefer the [tidyverse grammar](https://www.tmwr.org/tidyverse)), but data frames should also be fine to use. If you use my tools, everything will end up getting \~ tibblefied \~ anyway.     
    
The "SampleID" field wasn't discussed yet, but it's exactly what it sounds like! It must be unique, and it must match what you've called your samples in your sequencing data. (If you use this package, it's highly recommended that you call your sample IDs field exactly "SampleID" in both your metadata and ASV count table objects.)

You may also notice that there's some missing data (the NAs), which we'll talk about more later.

##### ASV count and taxonomy tables
    
In this made up toy example, we did 16S sequencing targeting the V4 region (following [the Kozich et al. 2013 protocol](https://journals.asm.org/doi/10.1128/aem.01043-13)) on these nasal swabs, then processed the sequencing data through [dada2](https://benjjneb.github.io/dada2/). The output we got from dada2 was:

1. An [ASV (amplicon sequencing variant) count table](https://benjjneb.github.io/dada2/) and   
2. Its associated taxonomy table.   

I do have my own wrapper for dada2+decontam. However, rather than using my exact dada2+decontam workflow, I'd highly recommend instead that you first follow the tutorials [for](https://benjjneb.github.io/dada2/tutorial.html) [each](https://benjjneb.github.io/decontam/vignettes/decontam_intro.html), as they very nicely describe how to use them and the considerations you should have for your own data.        

Next, let's looks at the example ASV count table `exampleASVtable`. (N.B.: The data doesn't necessarily strictly have to be an ASV table. Any sort of data in tabular format, e.g., OTU table, similar to the example **should** work.)

```{r asvexample}

exampleASVtable
```

Finally, let's look at the example taxonomy file `exampleTaxa`. This was also generated during the dada2 workflow, and must match the ASV table.

```{r taxaexample}

exampleTaxa
```

The ASV "names" are the literal sequences of the amplicons, so they're super long when viewed in this format. The ASV names must match in the ASV count and taxonomy tables. It would be stupefyingly difficult and annoying for a human to manually verify that they do match, but it's trivial for a computer to do so. We will check that the ASV names do indeed match later.        

All three example objects are also packaged together as a single list as object `exampleData`:

```{r allexample2}

str(exampleData, max.level = 1) # if you're really new to R, FYI, str() is an inbuilt R function that displays the STRucture of an R object, and I've set max.level to 1 so it will only display the first nested level (AKA, a minimal display here)


```

At this point in the tutorial, the existence of all the example objects in a single list isn't that helpful yet, but will become more so later. Later on, I'll demonstrate a function that you can use to list-ify your own data in a similar manner. This will allow you to have to type less, which is always nice.

### Step 5: Sanity check

#### Sanity check the data

Now that we're more familiar with in our main objects (exampleMetadata, exampleASVtable, exampleTaxa) we will do some basic sanity checks on these three objects.    

First, let's check the metadata object: 

```{r metacheck}
checkMeta(exampleMetadata)
```

You'll see there's a warning message that NAs were detected in the metadata table. This is not bad or wrong, and it's OK to have NAs! The warning is there to check with *you* that *you* were expecting to see some missing data. If you weren't, check that your metadata object was loaded in correctly. (Sometimes there can be unexpected issues with line breaks or non-standard characters, for example, when loading a real metadata file into R.)     

In this case, there are NAs in a few spots:

1. Demographic data is "missing" for the lab positive and negative controls, as that kind of information is not applicable/relevant/meaningful for them.    
2. Location is missing from the participant for sample "HC1". Let's say that this participant declined to share their geographic location, so it is indeed truly missing. With real life data, it's pretty normal to have some data not available for whatever reason. People much smarter than I am have [written](https://hbiostat.org/rmsc/missing.html) [extensively](https://link.springer.com/chapter/10.1007/978-1-4757-3462-1_3) [about](https://pubmed.ncbi.nlm.nih.gov/20338724/) [missing](https://www.appliedmissingdata.com) [data](https://pubmed.ncbi.nlm.nih.gov/17401454/), and how to deal with it, so that won't be discussed much more here.       

This is all fine and there are no glaring red flags with our metadata object.

(checkMeta takes two arguments; the first is your metadata object and the second is your sample IDs column. It's set so that 'SampleID' is the default so we didn't have to explicitly tell the function that. Try `checkMeta(exampleMetadata, "SampleType")` to see another example of a different type of warning you can get.)

___

OK, now let's also check on the ASV and taxonomy tables:

```{r asvcheck}
checkASV(exampleASVtable, exampleTaxa, exampleMetadata)
```

Since we didn't get any warnings from checkASV(), our three objects all passed my sanity checks. That isn't super helpful as an example, so instead, let's look at some included examples of "bad" ASV tables that will give warnings with the sanity checks:

```{r badcheck}
badasv1

checkASV(badasv1, exampleTaxa, exampleMetadata)
```

This is the least "bad" warning to get. We got a warning that no column named "SampleID" was found in the ASV count table. You don't *have* to follow this convention, but to use this package, it will make things much easier if you do. 

We got the prompt to run checkSampleID() on badasv1, so let's do that:

```{r badcheck1.1, eval=FALSE}
badasv1_fixed <- checkSampleID(badasv1)
```

This function is interactive, which is hard to demonstrate here, but this will have popped up on the console:    

`A column called 'SampleID' was not detected. What is the column name that you're using as your sample IDs?`   

I'll now type in the name, which was 'ID':    

`ID`   

Now it checks with me that it's OK to change the name:    

`Is it OK to change column name 'ID' to 'SampleID'? y/n:`

Type in `y` to accept the change. 

```{r badcheck1.2, eval=TRUE, echo=FALSE}
# behind the scenes to stuff to force the tutorial to work as intended
badasv1_fixed <- makeExample("asv")
```

Check that it looks good and we're no longer getting any warnings:

```{r badcheck1.3, eval=TRUE}
badasv1_fixed

checkASV(badasv1_fixed, exampleTaxa, exampleMetadata)
```

Great, we're all set. You can also use checkSampleID() on the metadata object; that's not demonstrated here as it's the same process, just with a different input object.     

Let's move on to much more serious problems.

```{r badcheck2.0, eval=TRUE}

checkASV(badasv2, exampleTaxa, exampleMetadata)
```

In this case, one of the ASVs was deleted from the count table, so now the number of ASVs in the count table doesn't match the number in the taxonomy table. If this happens with your data, you'll need to check that you're using the correct data and that nothing happened to corrupt it. You may need to re-run dada2 (or whatever workflow you used).    

Next, a similar example of something that can go wrong:

```{r badcheck3.0}

checkASV(badasv3, exampleTaxa, exampleMetadata)
```

One of the ASV names in the count table was changed, so it no longer matches its name in the taxonomy table. Like the previous example, this represents a different type of mismatch between the ASV count and taxonomy tables. Again, if this were to happen with your real data, make sure you're using the correct dataset and that something didn't get messed up somehow. Re-run the data processing steps if necessary.

Finally, one more example of something that can go wrong is that there's no match in the SampleIDs in the metadata and ASV count objects. Maybe you used a different number of padding zeroes, or got the wrong file somewhere.

```{r badcheck4.0}

checkASV(exampleASVtable, exampleTaxa, badmetadata1)
```

Since R can't figure out how to match the samples from the metadata and ASV objects, you won't be able to do any actual analysis with your metadata. This would need to be fixed before moving on. 

### Step 6: Quality check

#### Quality check the data

Since we're done with the basic sanity checks and the original objects `metadata`, `asvtable`, and `taxa` all looked good, now we can do an actual more interesting quality check of our data.    

As mentioned previously, lab positive and negative controls are VERY important and should be included at minimum in every single sequencing run.    

##### An aside to pontificate on negative controls

Negative controls are especially important with 16S data due the nature of the process: 1) bacteria and their DNA are ubiquitous and can live even in environments hostile to most other life, 2) the PCR protocol deliberately enriches for all bacteria in a semi-universal way. This means the data can be extremely susceptible to contamination. The details of this are out of the scope of this document, but your FIRST step should be improving your lab methods to reduce contamination potential as much as possible.

However, no matter how amazing you (or your colleagues) are in the lab, you'll probably still have at least some contamination. That's where the negative controls come in. I would recommend having at least one negative extraction control (e.g., extract some ultraclean water or sample buffer) per every extraction batch, and a PCR negative control for every PCR master mix batch.

If you've processed your data through [decontam](https://benjjneb.github.io/decontam/vignettes/decontam_intro.html) or another such tool, you've already bioinformatically removed some potential contaminants. I'd recommend doing this as part of your workflow before data analysis.   

However, for the first assessment of your negative controls, I recommend looking at the "raw" data, i.e., BEFORE it goes through `decontam` or other similar tool.   





## Placeholder

This is for me to remember to add to this document:    

identifyNegs and assessNegs.       
filtering.     
calcBetaDiv.       


___


# Acknowledgements

As mentioned above, I could not have done any of this without the benefit of what the work of others. These tools below were especially important:

* [mothur](https://mothur.org)   
* [qiime](https://qiime2.org)   
* [mgsat](https://github.com/andreyto/mgsat)   
* maaslin[2](https://huttenhower.sph.harvard.edu/maaslin/)/[3](https://huttenhower.sph.harvard.edu/maaslin3/)   
* [vegan](https://cran.r-project.org/web/packages/vegan/index.html)
* [tidyverse](https://tidyverse.tidyverse.org), especially [dplyr](https://dplyr.tidyverse.org) and [ggplot2](https://ggplot2.tidyverse.org). In addition to these packages, Hadley Wickham and team have written several extremely helpful [guides and tutorials](https://hadley.nz) on data science.
* [dada2 and decontam](https://callahanlab.cvm.ncsu.edu/software/)
* [Suite from Dr. Frank Harrell](https://hbiostat.org), especially [rms](https://cran.r-project.org/web/packages/rms/index.html) and [Hmisc](https://cran.r-project.org/web/packages/Hmisc/index.html).
* Colleague and physician-scientist [Dr. Christian Rosas-Salazar](https://pediatrics.vumc.org/person/christian-rosas-salazar-md-mph) is talented at many things, but has an especial knack for creating figures that are both beautiful and informative.   

More acknowledgements and more details to be added later
